{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL\n",
    "Con el fin de facilitar el análisis, el proceso de ETL se realizará de manera local a través de un notebook de python 2, el cuál trabajaremos por medio de dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Extracción\n",
    "Simplificado en la descarga del archivo desde el drop box, descomprimirlo y trabajarlo de manera local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATENTE</th>\n",
       "      <th>MARCA</th>\n",
       "      <th>MODELO</th>\n",
       "      <th>AGNO</th>\n",
       "      <th>ID_CLIENTE</th>\n",
       "      <th>COMUNA</th>\n",
       "      <th>REGION</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>ACTIVIDAD</th>\n",
       "      <th>TASACION</th>\n",
       "      <th>FEC_TRANSFERENCIA</th>\n",
       "      <th>COLOR2</th>\n",
       "      <th>EDAD</th>\n",
       "      <th>VIGENCIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>393A4B4C-085</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>RAV 4</td>\n",
       "      <td>2015</td>\n",
       "      <td>50838335</td>\n",
       "      <td>TEMUCO</td>\n",
       "      <td>09</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11947500,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BLANCO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1F3DB7E-F67</td>\n",
       "      <td>MAZDA</td>\n",
       "      <td>CX 5</td>\n",
       "      <td>2016</td>\n",
       "      <td>46322649</td>\n",
       "      <td>VILLA ALEMANA</td>\n",
       "      <td>05</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEGRO</td>\n",
       "      <td>38.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F6DBB2E6-A76</td>\n",
       "      <td>GREAT WALL</td>\n",
       "      <td>HAVAL NEW H3 2.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>36226810</td>\n",
       "      <td>ANTOFAGASTA</td>\n",
       "      <td>DE ANTOFAGASTA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEGRO</td>\n",
       "      <td>49.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EBCF63CD-99D</td>\n",
       "      <td>JEEP</td>\n",
       "      <td>COMPASS SPORT 2.4</td>\n",
       "      <td>2013</td>\n",
       "      <td>43482783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160418.0</td>\n",
       "      <td>GRIS</td>\n",
       "      <td>40.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FF38B368-B0F</td>\n",
       "      <td>SUBARU</td>\n",
       "      <td>FORESTER 2.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>25657273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GRIS</td>\n",
       "      <td>62.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PATENTE       MARCA             MODELO  AGNO  ID_CLIENTE  \\\n",
       "0  393A4B4C-085      TOYOTA              RAV 4  2015    50838335   \n",
       "1  B1F3DB7E-F67       MAZDA               CX 5  2016    46322649   \n",
       "2  F6DBB2E6-A76  GREAT WALL   HAVAL NEW H3 2.0  2014    36226810   \n",
       "3  EBCF63CD-99D        JEEP  COMPASS SPORT 2.4  2013    43482783   \n",
       "4  FF38B368-B0F      SUBARU       FORESTER 2.0  2017    25657273   \n",
       "\n",
       "          COMUNA          REGION SEXO  ACTIVIDAD     TASACION  \\\n",
       "0         TEMUCO              09    M        NaN   11947500,0   \n",
       "1  VILLA ALEMANA              05    M        NaN          NaN   \n",
       "2    ANTOFAGASTA  DE ANTOFAGASTA  NaN        NaN          NaN   \n",
       "3            NaN             NaN  NaN        NaN          NaN   \n",
       "4            NaN             NaN  NaN        NaN          NaN   \n",
       "\n",
       "   FEC_TRANSFERENCIA  COLOR2  EDAD VIGENCIA  \n",
       "0                NaN  BLANCO   NaN        N  \n",
       "1                NaN   NEGRO  38.0        S  \n",
       "2                NaN   NEGRO  49.0        S  \n",
       "3         20160418.0    GRIS  40.0        S  \n",
       "4                NaN    GRIS  62.0        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importar librerías necesarias\n",
    "import pandas as pd\n",
    "\n",
    "#Lectura de data, agregándo encabezados para facilitar su manipulación\n",
    "df = pd.read_csv(r'input\\bbdd prueba corp.csv', \n",
    "                 sep='\\073',\n",
    "                 names = [\"PATENTE\",\"MARCA\",\"MODELO\",\"AGNO\",\"ID_CLIENTE\",\"COMUNA\",\"REGION\",\"SEXO\",\"ACTIVIDAD\",\"TASACION\",\"FEC_TRANSFERENCIA\",\"COLOR2\",\"EDAD\",\"VIGENCIA\"]) \n",
    "\n",
    "#muestra de la data carga con cabecera\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformación\n",
    "Ocuparemos los formatos mas idóneos para el tipo de dato además de binarizar algunas columnas para facilitar su análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006969\n",
      "S    688992\n",
      "N    317977\n",
      "Name: VIGENCIA, dtype: int64\n",
      "PATENTE              100.00\n",
      "MARCA                 99.93\n",
      "MODELO                99.97\n",
      "AGNO                 100.00\n",
      "ID_CLIENTE           100.00\n",
      "COMUNA                57.07\n",
      "REGION                59.05\n",
      "SEXO                  12.18\n",
      "ACTIVIDAD             19.64\n",
      "TASACION              60.48\n",
      "FEC_TRANSFERENCIA     33.88\n",
      "COLOR2                98.75\n",
      "EDAD                  71.85\n",
      "VIGENCIA             100.00\n",
      "SM_REGION             59.05\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "print(len(df))\n",
    "print((df.notnull().sum()/len(df)*100).round(2))\n",
    "\n",
    "#transformar FEC_TRANSFERENCIA a formato fecha\n",
    "df['SM_FEC_TRANSFERENCIA'] = pd.to_datetime(df['FEC_TRANSFERENCIA'], format='%Y%m%d').dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "#binarizar variable vigencia\n",
    "df['VIGENCIA_BIN'] = np.where(df['VIGENCIA'] == 'S', 1, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinamos el porcentaje de datos poblados por variable y en base a su porcentaje determinaremos que variables consideraremos para analizar, de manera de trabajar con la mayor cantidad de datos posibles.\n",
    "\n",
    "Para nuestro análisis sólo consideraremos variables cuyo porcentaje de datos poblados sea mayor al 58%, descartando para el análisis: COMUNA, SEXO, ACTIVIDAD.\n",
    "\n",
    "Para la variable REGION normalizaremos su distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "01      6197\n",
       "02     29254\n",
       "03     13457\n",
       "04     16636\n",
       "05     48579\n",
       "06     19009\n",
       "07     15544\n",
       "08     45589\n",
       "09      9024\n",
       "10     14855\n",
       "11      2007\n",
       "12      5868\n",
       "13    302218\n",
       "14      5459\n",
       "15      2385\n",
       "Name: SM_REGION, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rellenar de 0 regiones con números menor a 0\n",
    "df['REGION_LPAD'] = df['REGION'].str.pad(width=2, side='left', fillchar='0')\n",
    "\n",
    "#normalizar regiones a números\n",
    "df.loc[df['REGION_LPAD'].str.contains('ÑUBLE|NUBLE|16', na=False), 'SM_REGION'] = '16'\n",
    "df.loc[df['REGION_LPAD'].str.contains('ARICA|PARINACOTA|15', na=False), 'SM_REGION'] = '15'\n",
    "df.loc[df['REGION_LPAD'].str.contains('RIOS|14', regex=True, na=False), 'SM_REGION'] = '14'\n",
    "df.loc[df['REGION_LPAD'].str.contains('METROPOLITANA|13', na=False), 'SM_REGION'] = '13'\n",
    "df.loc[df['REGION_LPAD'].str.contains('ANTARTICA|MAGALLANES|12', na=False), 'SM_REGION'] = '12'\n",
    "df.loc[df['REGION_LPAD'].str.contains('AYSEN|CARLOS|IBANEZ|11', na=False), 'SM_REGION'] = '11'\n",
    "df.loc[df['REGION_LPAD'].str.contains('LAGOS|10', na=False), 'SM_REGION'] = '10'\n",
    "df.loc[df['REGION_LPAD'].str.contains('ARAUCANIA|09', na=False), 'SM_REGION'] = '09'\n",
    "df.loc[df['REGION_LPAD'].str.contains('BIO|08', na=False), 'SM_REGION'] = '08'\n",
    "df.loc[df['REGION_LPAD'].str.contains('MAULE|07', na=False), 'SM_REGION'] = '07'\n",
    "df.loc[df['REGION_LPAD'].str.contains('HIGGINS|06', na=False), 'SM_REGION'] = '06'\n",
    "df.loc[df['REGION_LPAD'].str.contains('VALPARAISO|05', na=False), 'SM_REGION'] = '05'\n",
    "df.loc[df['REGION_LPAD'].str.contains('ARAUCANIA|04', na=False), 'SM_REGION'] = '04'\n",
    "df.loc[df['REGION_LPAD'].str.contains('COQUIMBO|03', na=False), 'SM_REGION'] = '03'\n",
    "df.loc[df['REGION_LPAD'].str.contains('ANTOFAGASTA|02', na=False), 'SM_REGION'] = '02'\n",
    "df.loc[df['REGION_LPAD'].str.contains('TARAPACA|01', na=False), 'SM_REGION'] = '01'\n",
    "\n",
    "df['SM_REGION'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para un futuro análisis realizaremos una división de las regiones por Zonas (Norte, Centro, Sur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e5dab1513204>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ZONA'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflag_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ZONA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "def flag_df(df):\n",
    "\n",
    "    if df['SM_REGION'] in ('15','01','02','03','04'):\n",
    "        return 'NORTE'\n",
    "    elif df['SM_REGION'] in ('05','06','07','08'):\n",
    "        return 'CENTRO'\n",
    "    elif df['SM_REGION'] in ('09','10','11','12','14'):\n",
    "        return 'SUR'\n",
    "    elif df['SM_REGION'] == '13':\n",
    "        return 'RM'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df['ZONA'] = df.apply(flag_df, axis = 1)\n",
    "\n",
    "df['ZONA'].value_counts()\n",
    "\n",
    "df['ZONA_NORTE'] = np.where(df['ZONA'] == 'NORTE', 1, 0)\n",
    "df['ZONA_CENTRO'] = np.where(df['ZONA'] == 'CENTRO', 1, 0)\n",
    "df['ZONA_SUR'] = np.where(df['ZONA'] == 'SUR', 1, 0)\n",
    "df['RM'] = np.where(df['ZONA'] == 'RM', 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardaremos la nueva tabla enriquecida para su análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['REGION']\n",
    "del df['VIGENCIA']\n",
    "del df['REGION_LPAD']\n",
    "del df['FEC_TRANSFERENCIA']\n",
    "\n",
    "df.to_csv(r'output\\bbdd_prueba_corp_enriched.csv', na_rep='NaN', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
